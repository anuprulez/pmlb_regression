{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble, metrics, cluster, tree\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "datasets = [\"228_elusage.tsv\", \"485_analcatdata_vehicle.tsv\", \"523_analcatdata_neavote.tsv\", \\\n",
    "            '663_rabe_266.tsv', '687_sleuth_ex1605.tsv']\n",
    "\n",
    "#datasets = [\"228_elusage.tsv\"]\n",
    "cv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Processing dataset: 228_elusage.tsv\n",
      "{'regression__max_depth': 7, 'regression__n_estimators': 100}\n",
      "Best score:  0.7417197569417688\n",
      "Finished dataset: 228_elusage.tsv\n",
      "------------------------------------------------------------\n",
      "Processing dataset: 485_analcatdata_vehicle.tsv\n",
      "{'regression__max_depth': 9, 'regression__n_estimators': 75}\n",
      "Best score:  0.6296412466704896\n",
      "Finished dataset: 485_analcatdata_vehicle.tsv\n",
      "------------------------------------------------------------\n",
      "Processing dataset: 523_analcatdata_neavote.tsv\n",
      "{'regression__max_depth': 3, 'regression__n_estimators': 1}\n",
      "Best score:  0.8861469521611808\n",
      "Finished dataset: 523_analcatdata_neavote.tsv\n",
      "------------------------------------------------------------\n",
      "Processing dataset: 663_rabe_266.tsv\n",
      "{'regression__max_depth': 9, 'regression__n_estimators': 40}\n",
      "Best score:  0.9834739552655704\n",
      "Finished dataset: 663_rabe_266.tsv\n",
      "------------------------------------------------------------\n",
      "Processing dataset: 687_sleuth_ex1605.tsv\n",
      "{'regression__max_depth': 3, 'regression__n_estimators': 100}\n",
      "Best score:  0.5868127179304012\n",
      "Finished dataset: 687_sleuth_ex1605.tsv\n",
      "------------------------------------------------------------\n",
      "Training finished\n",
      "Mean R2 square: \n",
      " 0.7655589257938822\n",
      "Total time taken: 10 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "regressor = Pipeline([\n",
    "  #('preprocessing', preprocessing.RobustScaler()),\n",
    "  ('regression', ensemble.RandomForestRegressor())\n",
    "])\n",
    "\n",
    "ard_parameters = [{ \\\n",
    "    #'regression__criterion': ['mse', 'mae'], \\\n",
    "    'regression__n_estimators': [1, 40, 75, 100], \\\n",
    "    'regression__max_depth': [1, 3, 5, 7, 9], \\\n",
    "    #'regression__min_weight_fraction_leaf': [0.0, 0.1, 0.25, 0.5, 1.0], \\\n",
    "    #'regression__max_features': [None, 'auto', 'log2', 'sqrt'], \\\n",
    "    #'regression__bootstrap': [True, False], \\\n",
    "    #'regression__random_state': [3111696] \\\n",
    "}]\n",
    "\n",
    "print('Training started...')\n",
    "dataset_accuracies = list()\n",
    "r2_scores = list()\n",
    "for d_set in datasets:\n",
    "    print(\"Processing dataset: %s\" % d_set)\n",
    "    data_path = \"data/\" + d_set\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "    label = df[\"target\"].copy()\n",
    "    data = df.drop(\"target\", axis=1)\n",
    "    optimized_regressor = GridSearchCV(regressor, ard_parameters, \\\n",
    "                                       cv=KFold(n_splits=cv, shuffle=True, random_state=3111696), \\\n",
    "                                       error_score=0, scoring='r2')\n",
    "    optimized_regressor.fit(data, label)\n",
    "    best_regressor = optimized_regressor.best_estimator_\n",
    "    best_result = optimized_regressor.cv_results_\n",
    "    print(optimized_regressor.best_params_)\n",
    "    best_score = optimized_regressor.best_score_\n",
    "    r2_scores.append(best_score)\n",
    "    print(\"Best score: \", best_score)\n",
    "    print(\"Finished dataset: %s\" % d_set)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "print('Training finished')\n",
    "print(\"Mean R2 square: \\n\", np.mean(r2_scores))\n",
    "end_time = time.time()\n",
    "print('Total time taken: %d seconds' % int(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 228_elusage.tsv\n",
      "100%|██████████| 500/500 [01:02<00:00,  6.59it/s, best loss: -0.7722333047839318]\n",
      "0.7722333047839318\n",
      "{'max_depth': 95.0, 'n_estimators': 11.0}\n",
      "-----------------------------------\n",
      "Dataset: 485_analcatdata_vehicle.tsv\n",
      "100%|██████████| 500/500 [01:07<00:00,  8.75it/s, best loss: -0.6814334093402792]\n",
      "0.6814334093402792\n",
      "{'max_depth': 68.0, 'n_estimators': 19.0}\n",
      "-----------------------------------\n",
      "Dataset: 523_analcatdata_neavote.tsv\n",
      "100%|██████████| 500/500 [01:04<00:00,  7.38it/s, best loss: -0.8847788022081454]\n",
      "0.8847788022081454\n",
      "{'max_depth': 22.0, 'n_estimators': 1.0}\n",
      "-----------------------------------\n",
      "Dataset: 663_rabe_266.tsv\n",
      "100%|██████████| 500/500 [01:15<00:00,  7.04it/s, best loss: -0.9866993715309423]\n",
      "0.9866993715309423\n",
      "{'max_depth': 64.0, 'n_estimators': 66.0}\n",
      "-----------------------------------\n",
      "Dataset: 687_sleuth_ex1605.tsv\n",
      "100%|██████████| 500/500 [02:27<00:00,  2.66it/s, best loss: -0.597096007323035] \n",
      "0.597096007323035\n",
      "{'max_depth': 2.0, 'n_estimators': 176.0}\n",
      "-----------------------------------\n",
      "Mean R2 square: \n",
      " 0.7844481790372668\n"
     ]
    }
   ],
   "source": [
    "# Parameter optimisation using Hyperopt (Bayesian optimisation)\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_eval = 150\n",
    "\n",
    "config = {\n",
    "    \"n_estimators\": \"1,100\",\n",
    "    \"max_depth\": \"1,100\",  \n",
    "}\n",
    "\n",
    "l_n_estimators = list(map(int, config[\"n_estimators\"].split(\",\")))\n",
    "l_max_depth = list(map(int, config[\"max_depth\"].split(\",\")))\n",
    "\n",
    "params = {\t    \n",
    "    \"n_estimators\": hp.quniform(\"n_estimators\", l_n_estimators[0], l_n_estimators[1], 1),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", l_max_depth[0], l_max_depth[1], 1),\n",
    "}\n",
    "\n",
    "best_acc_datasets = list()\n",
    "\n",
    "for d_set in datasets:\n",
    "    data_path = \"data/\" + d_set\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "    label = df[\"target\"].copy()\n",
    "    data = df.drop(\"target\", axis=1)\n",
    "    print(\"Dataset: %s\" % d_set)\n",
    "    def create_model(params):\n",
    "        clf = RandomForestRegressor(\n",
    "            n_estimators=int(params[\"n_estimators\"]),\n",
    "            max_depth=int(params[\"max_depth\"]),\n",
    "        )\n",
    "        r2_score = cross_val_score(clf, data, label, scoring='r2', cv=KFold(n_splits=cv, shuffle=True, random_state=3111696)).mean()\n",
    "        return {'loss': -r2_score, 'status': STATUS_OK}\n",
    "\n",
    "    # minimize the objective function using the set of parameters above\n",
    "    trials = Trials()\n",
    "    learned_params = fmin(create_model, params, trials=trials, algo=tpe.suggest, max_evals=max_eval)\n",
    "    loss_val = list()\n",
    "    for item in trials:\n",
    "        loss_val.append(item[\"result\"][\"loss\"])\n",
    "    best_acc = -min(loss_val)\n",
    "    best_acc_datasets.append(best_acc))\n",
    "    print(learned_params)\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "print(\"Mean R2 square: \\n\", np.mean(best_acc_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
